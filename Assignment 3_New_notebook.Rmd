# U.S Wage Dataset

#  The dataset uswages is drawn as a sample from the Current Population Survey in 1988.
# The following exercise is on the basic concepts behind the multivariate regression, confi- dence interval construction as well as prediction on a socially relevant topic.

# Make a numerical and graphical summary of the data, commenting on any features that you find interesting. Limit the output you present to a quantity that a busy reader would find sufficient to get a basic understanding of the data. Clean up any outliers or data errors if there are any.

# load data
library(faraway)
data(uswages)

# numerical summary
summary(uswages)

# graphic summary for continous variable, use scatterplot; for binary variables, use histogram
#Scatter Plot
plot.default(uswages[,1],main = "Real weekly wages in dollars",xlab = "ID",ylab = "")
#Histogram
hist(uswages[,4],main = "Race", xlab = "0=White 1=Black")

# By reading the summary above we can see the following observations,
#1. The dataset has experience values which is less that 0, we can remove these anomalies and proceed furthey with our analysis.
# 2. We can see there are few standard deviation are above the mean. So we can delete the wages which are 3 standard deviations above the mean.

# Cleaning process.
clean = subset(uswages, wage<1987.616 & exper>=0)

# name variables
wage=c(clean[,1])
edu=c(clean[,2])
exp=c(clean[,3])
race=c(clean[,4])
live=c(clean[,5])
ne=c(clean[,6])
mw=c(clean[,7])
we=c(clean[,8])
so=c(clean[,9])
part=c(clean[,10])

summary(clean)

# Fit a bivariate model with weekly wages as the response and years of education as the predictor.

wage.lm=lm(wage~edu, clean)

wage.lm

# Fit a multivariate model with weekly wages as the response and years of educa- tion and experience as predictors. Report and give a simple interpretation to the regression coefficient for years of education. Are these predictors significant?

lm_wage=lm(wage~edu+exp, clean)
lm_wage
# For every increase in education level there will be an increase of 50.869 in the respondent (Wage) and viceversa.

# Let the null hypothesis be H0 : β0 = β1 = β2 = 0 where β1 and β2 are the regression coefficients for the predictors years of education and experience respectively. Would you reject this hypothesis at confidence level %90? Hint: Use F-tests explained in the lecture slides for this computation. You can compute this by hand or using R.

# Sample code for regression and comparison of models with “anova” function
null=lm(wage~1,clean)
hypo=anova(null,lm_wage)
hypo
# performing F-test for 90% conf interval
fstat=var.test(wage,edu+exp,data=clean,conf.level = 0.90)
fstat
#P-value based on F-test
fstat$p.value
#fstat= predict(hypo,interval="confidence", level=0.90)

# The p-value of F-test is <2.2e-16(i.e., almost 0), which is less than the significance level of 0.05. 
# In conclusion, we can say that there is a significant difference between the two variances.So we reject the null hypothesis.

# Based on this model, for someone with 5 years of experience and 8 years of edu- cation, give a %90 confidence interval for his/her expected weekly wages.

# For checking the confidence interval of 90%, I am converting the data to a data frame with experience of 5 years and education of 8 years.

predi = data.frame(exp=c(5), edu=c(8))
# Make predictions
exp_edu=predict(lm_wage, predi,interval="confidence", level=0.90)
exp_edu
#We can tell that 90% of the time, the weekly wages will be in the range of 177.8701 to 235.9848.
#Fitted value is 206.9274.

# Consider a randomly selected individual from the Northeast who has 10 years of education and 5 years of experience. Does he/she expect to have more salary or less weekly salary compared to another candidate from the West with the same qualifications?

uswages <- data.frame(uswages,
                        region =
                          1*uswages$ne +
                          2*uswages$mw +
                          3*uswages$so +
                          4*uswages$we)

uswages$region = factor(uswages$region)
levels(uswages$region)= c("ne","mw","so","we")
clean <- subset(uswages, wage<1987.616 & exper>=0)

# name variables
wage=c(clean[,1])
edu=c(clean[,2])
exp=c(clean[,3])
race=c(clean[,4])
smsa=c(clean[,5])
pt=c(clean[,6])
region=c(clean[,7])
head(clean)

lm_nw <- lm(wage ~ educ + exper + region, data = clean)
summary(lm_nw)
head(lm_nw)

fitting_Ne <- data.frame(exper = c(5), educ = c(10), region = c('ne'))
pred_fitting_Ne=predict(lm_nw, fitting_Ne,interval="confidence", level=0.90)
head(pred_fitting_Ne)

fitting_We <- data.frame(exper = c(5), educ = c(10), region = c('we'))
pred_fitting_We=predict(lm_nw, fitting_We,interval="confidence", level=0.90)
head(pred_fitting_We)

# From the analysis above, we see that the wages are not significantly separated values ie the ranges are not apart, but the 

